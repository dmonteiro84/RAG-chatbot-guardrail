{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmont\\anaconda3\\envs\\cba-chatbot-guardrails-env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\dmont\\anaconda3\\envs\\cba-chatbot-guardrails-env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\dmont\\anaconda3\\envs\\cba-chatbot-guardrails-env\\Lib\\site-packages\\guardrails\\validator_service\\__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"response\": \"The product you are asking about is a Credit Card. It is designed to be a versatile tool for everyday purchases, offering rewards points to users. These rewards can be used for various benefits, which differ from card to card. However, it's always advisable to use the credit card wisely to avoid any potential debt issues.\"\n",
      "}\n",
      "ValidationOutcome(\n",
      "    call_id='2815933640736',\n",
      "    raw_llm_output='{\\n\"response\": \"The product you asked about is a Credit Card. It is a versatile card that you can use for your everyday purchases. One of the benefits of using this card is that you can earn rewards points. These reward points can typically be used to redeem various gifts or services, giving you added value for your spending.\"\\n}',\n",
      "    validation_summaries=None,\n",
      "    validated_output={\n",
      "        'response': 'The product you asked about is a Credit Card. It is a versatile card that you can use for your everyday purchases. One of the benefits of using this card is that you can earn rewards points. These reward points can typically be used to redeem various gifts or services, giving you added value for your spending.'\n",
      "    },\n",
      "    reask=None,\n",
      "    validation_passed=True,\n",
      "    error=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary components\n",
    "from src.retrieval import FaissRetriever\n",
    "from src.guardrail import Guardrails\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up OpenAI API key (assuming it's already set in your environment)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai.api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "class OpenAIGPT:\n",
    "    def __init__(self, retriever):\n",
    "        \"\"\"\n",
    "        Initialize the OpenAIGPT class using the FAISS retriever.\n",
    "        \"\"\"\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def retrieve_and_generate_response(self, user_query, k=3):\n",
    "        \"\"\"\n",
    "        This method performs two main tasks:\n",
    "        1. Retrieve relevant products using the FAISS retriever.\n",
    "        2. Generate a response using GPT-4 based on the retrieved product information.\n",
    "        \n",
    "        :param user_query: The user's query (e.g., \"Tell me about credit cards\").\n",
    "        :param k: The number of products to retrieve.\n",
    "        :return: A GPT-4 generated response.\n",
    "        \"\"\"\n",
    "        # Step 1: Retrieve relevant products from the knowledge base using FAISS\n",
    "        retrieved_products = self.retriever.search(user_query, k)\n",
    "        \n",
    "        # Step 2: Format the retrieved products into a text prompt for GPT-4\n",
    "        product_info = \"\\n\".join([\n",
    "            f\"Product: {p['product_name']}\\nDescription: {p['description']}\\n\" for p in retrieved_products\n",
    "        ])\n",
    "        \n",
    "        # Create the final prompt for GPT-4\n",
    "        prompt = f\"\"\"\n",
    "                    The user asked: '{user_query}'. Based on the following product information, provide a helpful response in the following JSON format:\n",
    "                    {{\n",
    "                    \"response\": \"Your generated response here\"\n",
    "                    }}\n",
    "                    {product_info}\n",
    "                    \"\"\"\n",
    "\n",
    "        # Step 3: Use OpenAI GPT-4 to generate a response based on the prompt\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Extract and return the text of the generated response\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "class OpenAIGPTWithGuardrails:\n",
    "    def __init__(self, retriever, guardrails):\n",
    "        \"\"\"\n",
    "        Initialize the OpenAIGPTWithGuardrails class using the FAISS retriever and Guardrails for validation.\n",
    "        \"\"\"\n",
    "        self.retriever = retriever\n",
    "        self.guardrails = guardrails\n",
    "\n",
    "    def retrieve_and_generate_response(self, user_query, k=3):\n",
    "        \"\"\"\n",
    "        Retrieve relevant products using FAISS and generate a response with GPT-4. Validate the response using Guardrails.\n",
    "        \n",
    "        :param user_query: The user's query (e.g., \"Tell me about credit cards\").\n",
    "        :param k: The number of products to retrieve.\n",
    "        :return: A GPT-4 generated and validated response.\n",
    "        \"\"\"\n",
    "        # Step 1: Retrieve relevant products from the knowledge base using FAISS\n",
    "        retrieved_products = self.retriever.search(user_query, k)\n",
    "        \n",
    "        # Step 2: Format the retrieved products into a text prompt for GPT-4\n",
    "        product_info = \"\\n\".join([\n",
    "            f\"Product: {p['product_name']}\\nDescription: {p['description']}\\n\" for p in retrieved_products\n",
    "        ])\n",
    "        \n",
    "        # Create the final prompt for GPT-4\n",
    "        prompt = f\"\"\"\n",
    "                    The user asked: '{user_query}'. Based on the following product information, provide a helpful response in the following JSON format:\n",
    "                    {{\n",
    "                    \"response\": \"Your generated response here\"\n",
    "                    }}\n",
    "                    {product_info}\n",
    "                    \"\"\"\n",
    "        \n",
    "        # Step 3: Use OpenAI GPT-4 to generate a response based on the prompt\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Step 4: Extract the generated response\n",
    "        generated_response = completion.choices[0].message.content.strip()\n",
    "        \n",
    "        # Step 5: Validate the response using Guardrails\n",
    "        validated_response = self.guardrails.validate_response(generated_response)\n",
    "        \n",
    "        return validated_response\n",
    "\n",
    "# Instantiate the FaissRetriever and Guardrails\n",
    "retriever = FaissRetriever(\"data/products.json\")\n",
    "guardrails = Guardrails()\n",
    "\n",
    "# Instantiate the GPT model without and with Guardrails\n",
    "gpt_without_guardrails = OpenAIGPT(retriever)\n",
    "gpt_with_guardrails = OpenAIGPTWithGuardrails(retriever, guardrails)\n",
    "\n",
    "# Test the system with an example query\n",
    "user_query = \"Tell me about the credit card.\"\n",
    "response_without_guardrails = gpt_without_guardrails.retrieve_and_generate_response(user_query)\n",
    "response_with_guardrails = gpt_with_guardrails.retrieve_and_generate_response(user_query)\n",
    "\n",
    "print(response_without_guardrails)\n",
    "print(response_with_guardrails)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cba-chatbot-guardrails-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
